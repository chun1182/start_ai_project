{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#フォルダリストを取得\n",
    "path='kill_me_baby_datasets'\n",
    "train_list=glob.glob(path+'/train/*')\n",
    "#testフォルダvalフォルダを作成\n",
    "for i in train_list:\n",
    "    os.makedirs(i.replace('train','test'))\n",
    "    os.makedirs(i.replace('train','val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in train_list:\n",
    "    #フォルダ内画像のパスを取得\n",
    "    pics = glob.glob(file+'/*.png')\n",
    "    pick_num = len(pics)//10\n",
    "    if not pick_num: continue\n",
    "    #20%を選び出す\n",
    "    choice = np.random.choice(pics, pick_num*2, replace=False)\n",
    "    #選んだ画像をtestとvalフォルダに移動\n",
    "    for test_pic in choice[:pick_num]:\n",
    "        shutil.move(test_pic, test_pic.replace('train','test'))\n",
    "    for val_pic in choice[pick_num:]:\n",
    "        shutil.move(val_pic, val_pic.replace('train','val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dpath):\n",
    "    path_list=glob.glob(dpath+'/*')\n",
    "    #画像ファイル、ラベルを入れる箱を用意\n",
    "    x=[]\n",
    "    y=[]\n",
    "\n",
    "    #フォルダ名でループを回す\n",
    "    for label,pic_path in enumerate(path_list):\n",
    "        #サブフォルダ内のファイルリストを取得\n",
    "        train_pic_list=glob.glob(pic_path+'/*.png')\n",
    "        print(pic_path, len(train_pic_list))\n",
    "        #画像ファイルを取得＋リサイズ、ラベルを用意\n",
    "        x += [cv2.resize(cv2.imread(i), (128,128)) for i in train_pic_list]\n",
    "        y += [label]*len(train_pic_list)\n",
    "\n",
    "    #画像をfloat32に変換正規化、ラベルをカテゴリカル化\n",
    "    x = np.float32(x)/255\n",
    "    y = keras.utils.to_categorical(y, len(train_list))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill_me_baby_datasets/train\\agiri 36\n",
      "kill_me_baby_datasets/train\\botsu 8\n",
      "kill_me_baby_datasets/train\\others 52\n",
      "kill_me_baby_datasets/train\\sonya 141\n",
      "kill_me_baby_datasets/train\\yasuna 273\n",
      "kill_me_baby_datasets/train\\yasuna_agiri 4\n",
      "kill_me_baby_datasets/train\\yasuna_sonya 39\n",
      "kill_me_baby_datasets/train\\yasuna_sonya_agiri 1\n",
      "kill_me_baby_datasets/val\\agiri 4\n",
      "kill_me_baby_datasets/val\\botsu 1\n",
      "kill_me_baby_datasets/val\\others 6\n",
      "kill_me_baby_datasets/val\\sonya 17\n",
      "kill_me_baby_datasets/val\\yasuna 34\n",
      "kill_me_baby_datasets/val\\yasuna_agiri 0\n",
      "kill_me_baby_datasets/val\\yasuna_sonya 4\n",
      "kill_me_baby_datasets/val\\yasuna_sonya_agiri 0\n",
      "kill_me_baby_datasets/test\\agiri 4\n",
      "kill_me_baby_datasets/test\\botsu 1\n",
      "kill_me_baby_datasets/test\\others 6\n",
      "kill_me_baby_datasets/test\\sonya 17\n",
      "kill_me_baby_datasets/test\\yasuna 34\n",
      "kill_me_baby_datasets/test\\yasuna_agiri 0\n",
      "kill_me_baby_datasets/test\\yasuna_sonya 4\n",
      "kill_me_baby_datasets/test\\yasuna_sonya_agiri 0\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = get_data(path+'/train')\n",
    "x_val, y_val = get_data(path+'/val')\n",
    "x_test, y_test = get_data(path+'/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 128, 128, 3) (554, 8)\n",
      "(66, 128, 128, 3) (66, 8)\n",
      "(66, 128, 128, 3) (66, 8)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten,GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_31 (Conv2D)           (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 128, 128, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 1,178,152\n",
      "Trainable params: 1,176,232\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (128, 128, 3)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill_me_baby_datasets/weights/weights_{epoch:02d}_{val_loss:.3f}_{val_acc:.3f}.h5\n",
      "use:csv_logger,checkpoint2,lr_reducer\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "#val_lossがbestの値を出したときにモデルの重みのみ(weight_only)を保存\n",
    "checkpoint_path = path+\"/weights/weights_{epoch:02d}_{val_loss:.3f}_{val_acc:.3f}.h5\"\n",
    "print(checkpoint_path)\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=0,\n",
    "                                 save_best_only=True, save_weights_only=True, mode='auto')  \n",
    "\n",
    "#accの向上がない=学習が止まっているとみてストップする。\n",
    "earlystop = EarlyStopping(monitor='acc', patience=15, verbose=1, mode='auto')\n",
    "    \n",
    "# CSV出力、下に重ねていく\n",
    "csv_logger = CSVLogger(path+'/weights/training.csv', append=True)\n",
    "    \n",
    "# val_lossの向上が見られない時に学習率を減らす。\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.1**0.5, cooldown=0, patience=5,\n",
    "                                   verbose=1, min_lr=0.5e-4)\n",
    "call_backs = [csv_logger,checkpoint, lr_reducer]\n",
    "print('use:csv_logger,checkpoint2,lr_reducer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 554 samples, validate on 66 samples\n",
      "Epoch 1/30\n",
      "554/554 [==============================] - 5s 9ms/step - loss: 1.1983 - acc: 0.6805 - val_loss: 4.1550 - val_acc: 0.5000\n",
      "Epoch 2/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.7039 - acc: 0.8087 - val_loss: 1.3937 - val_acc: 0.8030\n",
      "Epoch 3/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.6324 - acc: 0.7924 - val_loss: 0.5916 - val_acc: 0.8485\n",
      "Epoch 4/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.4764 - acc: 0.8412 - val_loss: 1.8574 - val_acc: 0.7424\n",
      "Epoch 5/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.5131 - acc: 0.8628 - val_loss: 0.3967 - val_acc: 0.8636\n",
      "Epoch 6/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.4227 - acc: 0.8520 - val_loss: 1.5476 - val_acc: 0.7424\n",
      "Epoch 7/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.4185 - acc: 0.8755 - val_loss: 2.0366 - val_acc: 0.6970\n",
      "Epoch 8/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.3377 - acc: 0.8917 - val_loss: 2.0127 - val_acc: 0.5455\n",
      "Epoch 9/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.3469 - acc: 0.8863 - val_loss: 0.3635 - val_acc: 0.8788\n",
      "Epoch 10/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.3471 - acc: 0.8917 - val_loss: 0.4413 - val_acc: 0.8485\n",
      "Epoch 11/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.2963 - acc: 0.9007 - val_loss: 0.7232 - val_acc: 0.7879\n",
      "Epoch 12/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.2258 - acc: 0.9332 - val_loss: 0.8585 - val_acc: 0.7879\n",
      "Epoch 13/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.2356 - acc: 0.9278 - val_loss: 0.8472 - val_acc: 0.7576\n",
      "Epoch 14/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.2210 - acc: 0.9332 - val_loss: 0.9106 - val_acc: 0.7424\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00031622778103685084.\n",
      "Epoch 15/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.2403 - acc: 0.9188 - val_loss: 0.5859 - val_acc: 0.8788\n",
      "Epoch 16/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.1840 - acc: 0.9513 - val_loss: 0.5675 - val_acc: 0.8182\n",
      "Epoch 17/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.1344 - acc: 0.9639 - val_loss: 0.2960 - val_acc: 0.9091\n",
      "Epoch 18/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.1089 - acc: 0.9693 - val_loss: 0.3254 - val_acc: 0.8939\n",
      "Epoch 19/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.1007 - acc: 0.9657 - val_loss: 0.3530 - val_acc: 0.8939\n",
      "Epoch 20/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.0822 - acc: 0.9801 - val_loss: 0.3439 - val_acc: 0.8485\n",
      "Epoch 21/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.0988 - acc: 0.9747 - val_loss: 0.2030 - val_acc: 0.9394\n",
      "Epoch 22/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.0887 - acc: 0.9783 - val_loss: 0.3714 - val_acc: 0.8788\n",
      "Epoch 23/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.0748 - acc: 0.9819 - val_loss: 0.2878 - val_acc: 0.9242\n",
      "Epoch 24/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.0789 - acc: 0.9856 - val_loss: 0.3775 - val_acc: 0.8485\n",
      "Epoch 25/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.0604 - acc: 0.9856 - val_loss: 0.6704 - val_acc: 0.8333\n",
      "Epoch 26/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.0808 - acc: 0.9765 - val_loss: 0.5445 - val_acc: 0.8485\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00010000000639606199.\n",
      "Epoch 27/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.0569 - acc: 0.9819 - val_loss: 0.5237 - val_acc: 0.8333\n",
      "Epoch 28/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.0611 - acc: 0.9838 - val_loss: 0.4975 - val_acc: 0.8333\n",
      "Epoch 29/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.0702 - acc: 0.9838 - val_loss: 0.4095 - val_acc: 0.8788\n",
      "Epoch 30/30\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.0491 - acc: 0.9910 - val_loss: 0.4971 - val_acc: 0.8636\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=32, epochs=30, verbose=1, callbacks=call_backs,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save_weights(path+'/weights/save.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill_me_baby_datasets/weights\\weights_21_0.203_0.939.h5\n"
     ]
    }
   ],
   "source": [
    "weight_list=glob.glob(path+'/weights/*.h5')\n",
    "print(weight_list[-1])\n",
    "model.load_weights(weight_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.534051750645493\n",
      "Test accuracy: 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions,shape (66, 8)\n",
      "[[ 3  0  1  0  0  0]\n",
      " [ 0  1  0  0  0  0]\n",
      " [ 1  0  3  1  1  0]\n",
      " [ 0  0  0 17  0  0]\n",
      " [ 0  0  0  0 34  0]\n",
      " [ 1  0  0  0  1  2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "print('predictions,shape', predictions.shape)\n",
    "predict_classes = np.argmax(predictions, 1)\n",
    "true_classes = np.argmax(y_test, 1)\n",
    "print(confusion_matrix(true_classes, predict_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
